{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#Дерево-решений\" data-toc-modified-id=\"Дерево-решений-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Дерево решений</a></span></li><li><span><a href=\"#Случайный-лес\" data-toc-modified-id=\"Случайный-лес-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Случайный лес</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#*BERT\" data-toc-modified-id=\"*BERT-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>*BERT</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузитье и подготовить данные.\n",
    "2. Обучить разные модели. \n",
    "3. Сделатье выводы.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# загрузим все необходимые библиотеки\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним датасет в переменную **commemts**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = pd.read_csv('C:\\\\Users\\\\503so\\\\OneDrive\\\\Desktop\\\\praktikum-to-git\\\\13_toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на первые 5 строк таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И изучим общую информацию о имеющемся датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "comments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наш датасет содержит 159571 строку (объект) и 2 столбца: обучающий признак - текст комментария, и целевой признак - принадлежность комментария к категории \"токсичных\".\n",
    "\n",
    "Также видим, что наблюдается ощутимый дисбаланс классов: 143346 объектов относятся к категории *не токсичных* (класс 0), и всего 16225 - к категории *токсичных* (класс 1). Или 89.8% и 10.2% соответственно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим список `corpus`, в котором сохраним все комментарии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(comments['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функции **lemm** и **clear_text**. Первая будет возвращать леммы слов в комментариях, вторая - очищать текст от \"посторонних\" символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm(text):\n",
    "    lemm_list = nltk.stem.WordNetLemmatizer()\n",
    "    return \"\".join(lemm_list.lemmatize(word) for word in text)\n",
    "        \n",
    "    \n",
    "def clear_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text) \n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим новый корпус `corpus_clear` на основе исходного корпуса с \"очищенными\" предложениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 34s, sys: 794 ms, total: 5min 34s\n",
      "Wall time: 5min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus_clear = []\n",
    "for text in corpus:\n",
    "    corpus_clear.append(clear_text(lemm(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asd', 'asd']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x.lower(), [\"asD\", \"Asd\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на первые два предложения исходного корпуса и корпуса очищенных текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n",
       " \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Explanation Why the edits made under my username Hardcore Metallica Fan were reverted They weren t vandalisms just closure on some GAs after I voted at New York Dolls FAC And please don t remove the template from the talk page since I m retired now',\n",
       " 'D aww He matches this background colour I m seemingly stuck with Thanks talk January UTC']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_clear[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим из библиотеки **nltk** стоп-слова для языка \"*english*\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве обучающего набора данных выберем результат TF-IDF-векторизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = corpus_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = comments['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При разделении выборок на обучающую и тестовую, установим размер тестовой выборки, равный 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test = train_test_split(features, test_size=0.3, shuffle=False)\n",
    "target_train, target_test = train_test_split(target, test_size=0.3, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим переменную `count_tf_idf` для выполнения TF-IDF-векторизации корпуса текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим векторизатор на обучающей выборке \"очищенного\" корпуса текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.1 s, sys: 116 ms, total: 11.2 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf_idf_train = count_tf_idf.fit_transform(features_train)\n",
    "tf_idf_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию `toxic_score`, которая будет вычислять и выводить на экран три метрики точности предсказаний: метрику f1_score, полноту и точность. Поскольку задача модели - идентифицировать \"токсичные\" комментарии, чтобы отправить их на модерацию, в связке показателей точность-полнота важнее представляется именно полнота. Лучше, если максимальное количество \"токсичных\" комментариев будет отправлено на модерацию. При этом, если пострадает точность, то на модерацию будут отправлены комментарии, ложно тдентифицированные моделью как токсичные. В данном случае можно говорить о конфликте скорости и качества: при большем количестве сообщений, отправленных на модерацию, на их обработку уйдет больше времени, но у пользователей сайта будет меньше шансов наткнуться на неприемлемый контент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toxic_score(test, predictions):\n",
    "    f1 = f1_score(test, predictions)\n",
    "    recall = recall_score(test, predictions)\n",
    "    precision = precision_score(test, predictions)\n",
    "    print('Значение метрики f1_score: {:.3f}'.format(f1))\n",
    "    print('Значение полноты: {:.3f}'.format(recall))\n",
    "    print('Значение точности: {:.3f}'.format(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку мы имеем дело с ярко выраженным дисбалансом классов, передадим модели логистической регрессии параметр `class_weight='balanced'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем на экран размерности полученных выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111699, 137131)\n",
      "(47872, 137131)\n",
      "(111699,)\n",
      "(47872,)\n"
     ]
    }
   ],
   "source": [
    "print(tf_idf_train.shape)\n",
    "print(tf_idf_test.shape)\n",
    "print(target_train.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение метрики f1_score: 0.755\n",
      "Значение полноты: 0.845\n",
      "Значение точности: 0.682\n",
      "CPU times: user 8.33 s, sys: 5.03 s, total: 13.4 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(tf_idf_train, target_train)\n",
    "predictions = model.predict(tf_idf_test)\n",
    "toxic_score(target_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество токсичных комментариев по предсказаниям: 6006\n",
      "Реальное количество токсичных комментариев: 4844\n"
     ]
    }
   ],
   "source": [
    "print('Количество токсичных комментариев по предсказаниям:', pd.Series(predictions).value_counts()[1])\n",
    "print('Реальное количество токсичных комментариев:', pd.Series(target_test).value_counts()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На предсказаниях логистической регрессии мы получили величину метрики **f1_score**, равную **0.755**.\n",
    "Также видим, что модель отнесла к \"токсичным\" большее количество комментариев, чем есть на самом деле (при том, что какие-то могла пропустить как приемлемые). Однако это меньшая из двух зол."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший результат: 0.5731570061902082\n",
      "Лучшая глубина дерева: 9\n",
      "CPU times: user 37.6 s, sys: 26.2 ms, total: 37.7 s\n",
      "Wall time: 37.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "for depth in range(1,10):\n",
    "    model_t = DecisionTreeClassifier(random_state=503350, max_depth=depth)\n",
    "    model_t.fit(tf_idf_train, target_train)\n",
    "    predictions_t = model_t.predict(tf_idf_test)\n",
    "    score_t = f1_score(target_test, predictions_t)\n",
    "    if score_t > best_result:\n",
    "        best_result = score_t\n",
    "        best_depth = depth\n",
    "        \n",
    "print('Лучший результат:', best_result)\n",
    "print('Лучшая глубина дерева:', best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier(random_state=503350, max_depth = best_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение метрики f1_score: 0.573\n",
      "Значение полноты: 0.421\n",
      "Значение точности: 0.900\n",
      "CPU times: user 7.38 s, sys: 0 ns, total: 7.38 s\n",
      "Wall time: 7.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_tree.fit(tf_idf_train, target_train)\n",
    "predictions_tree = model_tree.predict(tf_idf_test)\n",
    "toxic_score(target_test, predictions_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший результат: 0.36912812190064015\n",
      "Лучшая глубина дерева: 14\n",
      "Лучшее количество наблюдателей: 90\n",
      "CPU times: user 5min 28s, sys: 261 ms, total: 5min 28s\n",
      "Wall time: 5min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_result = 0\n",
    "best_depth = 0\n",
    "best_est = 0\n",
    "for depth_f in range(5, 15):\n",
    "    for n_est in range(10, 100, 10):\n",
    "        model_f = RandomForestClassifier(class_weight='balanced', \n",
    "                                         random_state=503350,\n",
    "                                         max_depth=depth_f,\n",
    "                                         n_estimators=n_est)\n",
    "        model_f.fit(tf_idf_train, target_train)\n",
    "        predictions_f = model_f.predict(tf_idf_test)\n",
    "        score_f = f1_score(target_test, predictions_f)\n",
    "        if score_f > best_result:\n",
    "            best_result_f = score_f\n",
    "            best_depth_f = depth_f\n",
    "            best_est = n_est\n",
    "        \n",
    "print('Лучший результат:', best_result_f)\n",
    "print('Лучшая глубина дерева:', best_depth_f)\n",
    "print('Лучшее количество наблюдателей:', best_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = RandomForestClassifier(class_weight='balanced', \n",
    "                                      random_state=503350,\n",
    "                                      max_depth = best_depth_f,\n",
    "                                      n_estimators = best_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение метрики f1_score: 0.369\n",
      "Значение полноты: 0.845\n",
      "Значение точности: 0.236\n",
      "CPU times: user 8.39 s, sys: 0 ns, total: 8.39 s\n",
      "Wall time: 8.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_forest.fit(tf_idf_train, target_train)\n",
    "predictions_forest = model_forest.predict(tf_idf_test)\n",
    "toxic_score(target_test, predictions_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По результатам выполненной работы можем заключить:\n",
    "1. Логистическая регрессия поепзала результат, лучший, чем дерево решений: 0.755 против 0.573. Результат случайного леса оказался еще хуже - 0.37 (возможно, модель переобучилась).\n",
    "2. Не всегда имеет смысл делать лемматизацию текстов корпуса: лемматизация не только занимает большое количество времени, но и может снизить качество модели в частном случае. Т.о. стоит начинать с самой простой модели, и постепенно добавалять шаги предобработки и гиперпараметры модели, следя за результатом метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
